{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BbvOaDLdiRU6",
        "outputId": "11521597-21d9-4708-c275-e4d7d4c0da75"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.82)] [1 InRelease 5,484 B/129\r                                                                               \rHit:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Hit:4 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:5 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Get:6 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:7 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,788 kB]\n",
            "Get:8 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,243 kB]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease [18.1 kB]\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:12 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:13 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,833 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,542 kB]\n",
            "Get:15 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,690 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,099 kB]\n",
            "Get:17 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy/main amd64 Packages [34.3 kB]\n",
            "Fetched 20.5 MB in 2s (8,367 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr is already the newest version (4.1.1-2.1build1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 32 not upgraded.\n",
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (11.1.0)\n",
            "Collecting jiwer\n",
            "  Downloading jiwer-3.1.0-py3-none-any.whl.metadata (2.6 kB)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.50.3)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from jiwer) (8.1.8)\n",
            "Collecting rapidfuzz>=3.9.7 (from jiwer)\n",
            "  Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.30.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2.0.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (2025.3.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.26.0->transformers) (4.13.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Downloading jiwer-3.1.0-py3-none-any.whl (22 kB)\n",
            "Downloading rapidfuzz-3.13.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rapidfuzz, pytesseract, jiwer\n",
            "Successfully installed jiwer-3.1.0 pytesseract-0.3.13 rapidfuzz-3.13.0\n"
          ]
        }
      ],
      "source": [
        "# Install Tesseract OCR\n",
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr\n",
        "# Install pytesseract and Pillow for Python\n",
        "!pip install pytesseract Pillow jiwer transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "from PIL import Image\n",
        "from jiwer import wer\n",
        "from transformers import MarianMTModel, MarianTokenizer, pipeline\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import string\n",
        "import torch\n",
        "from nltk.translate.bleu_score import sentence_bleu\n",
        "\n",
        "# Initialize Sentence-BERT model for semantic similarity (multilingual version)\n",
        "semantic_model = SentenceTransformer('sentence-transformers/distiluse-base-multilingual-cased-v2')\n",
        "\n",
        "def calculate_bleu(reference, hypothesis):\n",
        "    reference = [reference.split()]\n",
        "    hypothesis = hypothesis.split()\n",
        "    return sentence_bleu(reference, hypothesis)\n",
        "\n",
        "\n",
        "def calculate_wer(reference, hypothesis):\n",
        "    return wer(reference, hypothesis)\n",
        "\n",
        "\n",
        "def normalize_text(text):\n",
        "    \"\"\"More robust text normalization\"\"\"\n",
        "    text = text.lower().strip()\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
        "    text = ' '.join(text.split())\n",
        "    return text\n",
        "\n",
        "\n",
        "def ocr_extraction(image_path):\n",
        "    try:\n",
        "        img = Image.open(image_path)\n",
        "        return pytesseract.image_to_string(img)\n",
        "    except Exception as e:\n",
        "        print(f\"OCR Error: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "\n",
        "def load_translation_model():\n",
        "    model_name = \"Helsinki-NLP/opus-mt-en-fr\"\n",
        "    return (\n",
        "        MarianMTModel.from_pretrained(model_name),\n",
        "        MarianTokenizer.from_pretrained(model_name)\n",
        "    )\n",
        "\n",
        "def translate_text(model, tokenizer, text):\n",
        "    try:\n",
        "        inputs = tokenizer([text], return_tensors=\"pt\", truncation=True, max_length=512)\n",
        "        translated = model.generate(**inputs)\n",
        "        return tokenizer.decode(translated[0], skip_special_tokens=True)\n",
        "    except Exception as e:\n",
        "        print(f\"Translation Error: {str(e)}\")\n",
        "        return \"\"\n",
        "\n",
        "# Semantic similarity calculation using Sentence-BERT\n",
        "def calculate_semantic_similarity(ref, hyp):\n",
        "    \"\"\"Calculate cosine similarity between reference and hypothesis\"\"\"\n",
        "    if not ref or not hyp:\n",
        "        return 0.0\n",
        "\n",
        "    # Encode both sentences\n",
        "    embeddings = semantic_model.encode([ref, hyp], convert_to_tensor=True)\n",
        "\n",
        "    # Calculate cosine similarity\n",
        "    cosine_score = util.pytorch_cos_sim(embeddings[0], embeddings[1])\n",
        "    return cosine_score.item()\n",
        "\n",
        "\n",
        "def evaluate_ocr(ocr_output, ground_truth_ocr):\n",
        "    clean_ocr = normalize_text(ocr_output)\n",
        "    clean_gt = normalize_text(ground_truth_ocr)\n",
        "    return wer(clean_gt, clean_ocr)\n",
        "\n",
        "\n",
        "def evaluate_translation(ocr_text, ground_truth_fr, model, tokenizer):\n",
        "    \"\"\"Evaluate translation using semantic similarity\"\"\"\n",
        "    # Translate OCR text\n",
        "    translated = translate_text(model, tokenizer, normalize_text(ocr_text))\n",
        "\n",
        "    # Clean both texts\n",
        "    clean_translation = normalize_text(translated)\n",
        "    clean_ground_truth = normalize_text(ground_truth_fr)\n",
        "\n",
        "    # Calculate scores\n",
        "    similarity = calculate_semantic_similarity(clean_ground_truth, clean_translation)\n",
        "    bleu_score = calculate_bleu(clean_ground_truth, clean_translation)\n",
        "\n",
        "    return similarity, bleu_score, translated  # Return both scores and translation\n",
        "\n",
        "def process_image_for_evaluation(image_path, ground_truth_ocr, ground_truth_fr):\n",
        "    \"\"\"Complete processing pipeline\"\"\"\n",
        "    # OCR Extraction\n",
        "    ocr_text = ocr_extraction(image_path)\n",
        "    print(f\"Extracted OCR Text:\\n{ocr_text}\\n\")\n",
        "\n",
        "    # OCR Evaluation\n",
        "    wer_score = evaluate_ocr(ocr_text, ground_truth_ocr)\n",
        "    print(f\"OCR WER: {wer_score:.4f}\")\n",
        "\n",
        "    # Load translation model\n",
        "    model, tokenizer = load_translation_model()\n",
        "\n",
        "    # Translation Evaluation\n",
        "    similarity, bleu, translated_text = evaluate_translation(ocr_text, ground_truth_fr, model, tokenizer)\n",
        "\n",
        "    # Print translation and scores\n",
        "    print(f\"\\nGenerated Translation:\\n{translated_text}\\n\")\n",
        "    print(f\"Semantic Similarity Score: {similarity:.4f}\")\n",
        "    print(f\"BLEU Score: {bleu:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    image_path = \"ocr2.png\"  # Update with your image path\n",
        "\n",
        "    ground_truth_ocr = \"2.3 Deep3DFace Deep3DFace is the most advanced model in this comparison, using a deep neural network to provide highly detailed 3D face reconstructions, including accurate facial expressions and fine details like skin texture. This model excels in producing realistic faces and is suited for tasks that require high accuracy. Strengths: • High Detail and Realism: Deep3DFace captures fine details of the face. • Expression Transfer: Deep3DFace excels at transferring facial expressions from one face to another with precision, making it perfect for applications like video game avatars or virtual reality. Limitations: • Processing Time: Deep3DFace takes the longest to process among the three models due to the high level of detail it captures, making it less suitable for real-time applications. • High Computational Requirements: This model requires a powerful system with advanced GPU capabilities to run efficiently, particularly when processing large datasets. Example Use: Deep3DFace is ideal for applications, where realistic and detailed 3D face modeling is required, and processing time is less of a concern. In summary: • If speed and real-time performance are the priority, FaceMesh is the best option. • If more accuracy in facial expressions is required, 3DDFA offers a balanced choice between speed and detail. • For the highest quality and realism in 3D face reconstruction and expression transfer, Deep3DFace is the best model, though it requires more processing power.\"\n",
        "    # ground_truth_ocr = \"During a shift in the operating room, Radar O'Reilly (Gary Burghoff) enters and informs Henry Blake that Blake has received all of the needed Army service points to be discharged and sent home. Henry begins planning his return and places a telephone call to Bloomington, Illinois, to inform his wife and family of the good news. Majors Margaret Houlihan (Loretta Swit) and Frank Burns (Larry Linville) celebrate privately that Frank will become the unit commander. Henry and Radar share a sentimental moment in which young Radar describes Henry as a father figure, and gives Henry an inscribed Winchester cartridge; a surprised Henry returns the favor by spontaneously giving Radar a rectal thermometer that once belonged to his father. On the night before Henry's departure, Hawkeye Pierce (Alan Alda), Trapper McIntyre (Wayne Rogers), and Radar throw a drunken going-away party for Henry at Rosie's Bar and Grill, and present him with a tailored civilian suit as a parting gift. The next morning, Frank attempts to assemble the company for a formal send-off, but Hawkeye and Trapper are out of uniform and unshaven, and Corporal Klinger (Jamie Farr) wears a particularly elaborate dress made specially for the occasion. Henry arrives in his new suit, and Frank and Margaret give Blake a formal salute, but Henry chides Frank for being too disciplined. Henry's affectionate individual goodbyes to the others are cut short by the imminent arrival of his helicopter, but Hawkeye pulls him aside and persuades him to give a long parting kiss to Margaret, to her surprise and Frank's annoyance.\"\n",
        "    # ground_truth_french = \"Lors d'une garde au bloc opératoire, Radar O'Reilly (Gary Burghoff) entre et informe Henry Blake que ce dernier a accumulé tous les points de service militaire nécessaires pour être démobilisé et renvoyé chez lui. Henry prépare son retour et téléphone à Bloomington, dans l'Illinois, pour annoncer la bonne nouvelle à sa femme et à sa famille. Les majors Margaret Houlihan (Loretta Swit) et Frank Burns (Larry Linville) célèbrent en privé la nomination de Frank au poste de commandant d'unité. Henry et Radar partagent un moment d'émotion intense : le jeune Radar décrit Henry comme une figure paternelle et lui offre une cartouche Winchester gravée. Henry, surpris, lui rend la pareille en lui offrant spontanément un thermomètre rectal ayant appartenu à son père. La veille du départ d'Henry, Hawkeye Pierce (Alan Alda), Trapper McIntyre (Wayne Rogers) et Radar organisent une fête d'adieu arrosée pour Henry au Rosie's Bar and Grill, et lui offrent un costume civil sur mesure en guise de cadeau d'adieu. Le lendemain matin, Frank tente de réunir la compagnie pour un départ officiel, mais Hawkeye et Trapper sont en civil et mal rasés, et le caporal Klinger (Jamie Farr) porte une robe particulièrement élaborée, confectionnée spécialement pour l'occasion. Henry arrive dans son nouveau costume, et Frank et Margaret saluent Blake de manière solennelle, mais Henry reproche à Frank d'être trop discipliné. Les adieux affectueux d'Henry aux autres sont interrompus par l'arrivée imminente de son hélicoptère, mais Hawkeye le prend à part et le persuade d'embrasser longuement Margaret, à la surprise de celle-ci et au grand dam de Frank.\"\n",
        "    ground_truth_french = \"2.3 Deep3DFace Deep3DFace est le modèle le plus avancé de cette comparaison. Il utilise un réseau neuronal profond pour fournir des reconstructions faciales 3D très détaillées, incluant des expressions faciales précises et des détails fins comme la texture de la peau. Ce modèle excelle dans la création de visages réalistes et convient aux tâches exigeant une grande précision. Points forts : • Détail et réalisme élevés : Deep3DFace capture les détails les plus fins du visage. • Transfert d'expressions : Deep3DFace excelle dans le transfert précis des expressions faciales d'un visage à l'autre, ce qui le rend idéal pour des applications telles que les avatars de jeux vidéo ou la réalité virtuelle. Contraintes : • Temps de traitement : Deep3DFace est le modèle le plus long à traiter parmi les trois en raison du niveau de détail élevé qu'il capture, ce qui le rend moins adapté aux applications temps réel. • Besoins de calcul élevés : Ce modèle nécessite un système puissant doté de capacités GPU avancées pour fonctionner efficacement, en particulier lors du traitement de grands ensembles de données. Exemple d'utilisation : Deep3DFace est idéal pour les applications nécessitant une modélisation faciale 3D réaliste et détaillée, et où le temps de traitement est moins important. En résumé : • Si la vitesse et les performances en temps réel sont primordiales, FaceMesh est la meilleure option. • Si une plus grande précision des expressions faciales est requise, 3DDFA offre un choix équilibré entre vitesse et détail. • Pour une qualité et un réalisme optimaux lors de la reconstruction faciale 3D et du transfert d'expressions, Deep3DFace est le meilleur modèle, bien qu'il nécessite une puissance de traitement plus importante.\"\n",
        "\n",
        "    process_image_for_evaluation(image_path, ground_truth_ocr, ground_truth_french)"
      ],
      "metadata": {
        "id": "OGBa3diliUHq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c4b08f06-c2be-4457-8314-3a96c6ba67f0"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted OCR Text:\n",
            "2.3. Deep3DFace\n",
            "\n",
            "Deep3DFace is the most advanced model in this comparison, using a deep neural network to provide highly detailed 3D\n",
            "face reconstructions, including accurate facial expressions and fine details like skin texture. This model excels in producing\n",
            "realistic faces and is suited for tasks that require high accuracy.\n",
            "\n",
            "Strengths:\n",
            "\n",
            "e High Detail and Realism: Deep3DFace captures fine details of the face.\n",
            "\n",
            "e Expression Transfer: Deep3DFace excels at transferring facial expressions from one face to another with precision,\n",
            "making it perfect for applications like video game avatars or virtual reality.\n",
            "\n",
            "Limitations:\n",
            "\n",
            "e Processing Time: Deep3DFace takes the longest to process among the three models due to the high level of detail it\n",
            "captures, making it less suitable for real-time applications.\n",
            "\n",
            "e High Computational Requirements: This model requires a powerful system with advanced GPU capabilities to\n",
            "run efficiently, particularly when processing large datasets.\n",
            "\n",
            "Example Use: Deep3DFace is ideal for applications, where realistic and detailed 3D face modeling is required, and\n",
            "processing time is less of a concern.\n",
            "In summary:\n",
            "\n",
            "e If speed and real-time performance are the priority, FaceMesh is the best option.\n",
            "e If more accuracy in facial expressions is required, 3DDFA offers a balanced choice between speed and detail.\n",
            "\n",
            "e For the highest quality and realism in 3D face reconstruction and expression transfer, Deep3DFace is the best model,\n",
            "though it requires more processing power.\n",
            "\f\n",
            "\n",
            "OCR WER: 0.0311\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n",
            "  warnings.warn(\"Recommended: pip install sacremoses.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Generated Translation:\n",
            "23 deep3dface deep3dface est le modèle le plus avancé dans cette comparaison en utilisant un réseau neuronal profond pour fournir des reconstructions 3d très détaillées comprenant des expressions faciales précises et des détails fins comme la texture de la peau ce modèle excelle dans la production de visages réalistes et est adapté aux tâches qui nécessitent des forces de haute précision e haute précision et réalisme deep3dface capture des détails fins du transfert de visage e expression deep3dface excelle dans le transfert d'expressions faciales d'un visage à l'autre avec précision ce qui le rend parfait pour des applications comme les avatars de jeu vidéo ou les limitations de réalité virtuelle e traitement deep3dface prend le plus de temps pour traiter parmi les trois modèles en raison du haut niveau de détail qu'il capture rend moins adapté pour des applications en temps réel e hautes exigences informatiques ce modèle nécessite un système puissant avec des capacités avancées gpu pour fonctionner efficacement particulièrement lorsque le traitement de grands ensembles de données exemple utilisent deep3dface est idéal pour des applications où la modélisation 3d visage réaliste et détaillée est nécessaire et le temps de traitement est moins préoccupant en résumé e si la vitesse et les performances en temps réel sont la meilleure option e si l'expression de visage est la meilleure\n",
            "\n",
            "Semantic Similarity Score: 0.9838\n",
            "BLEU Score: 0.3438\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "ySJ155AeUnnl"
      },
      "execution_count": 31,
      "outputs": []
    }
  ]
}